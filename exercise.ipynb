{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import joblib\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from src.utils import order_templates\n",
    "from src.utils_2 import encode_templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all ecg templates and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load a dataset recording ECG during the use of a wheelchair.\n",
    "\n",
    "There are six different levels (level 0 to 5), each level describing an increase in intensity (speed) with which the subject is driving. 0 is the stillstand level.\n",
    "\n",
    "First, let's load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/ecg_data.pkl', 'rb') as f:\n",
    "    loaded_ecg_data = pickle.load(f)\n",
    "\n",
    "templates_loaded = loaded_ecg_data['templates']\n",
    "labels_loaded = loaded_ecg_data['labels']\n",
    "\n",
    "class_template_mapping = order_templates(templates_loaded, labels_loaded)\n",
    "z_class_template_mapping = encode_templates(class_template_mapping)\n",
    "\n",
    "for key, value in z_class_template_mapping.items():\n",
    "    print(\"Level:\", key + 1, \"| #templates: \", len(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see which intensity levels (or classes) we have.\n",
    "\n",
    "In addition, the number of templates per intensity level is listed.\n",
    "\n",
    "Now, let's prepare the data for a simple plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_mapping = {}\n",
    "for key, value in z_class_template_mapping.items():\n",
    "    key = key + 1\n",
    "    numpy_mapping[key] = np.array(value)\n",
    "\n",
    "#Â Only take 100 latent space samples per class (comp. too expensive otherwise)\n",
    "\n",
    "numpy_mapping_small = {}\n",
    "for key in numpy_mapping.keys():\n",
    "    numpy_mapping_small[key] = numpy_mapping[key][:100]\n",
    "\n",
    "for key, value in numpy_mapping_small.items():\n",
    "    print(key, len(value))\n",
    "numpy_mapping = numpy_mapping_small\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot two latent dimensions in a 2D plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure and axis\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "\n",
    "# Define colors for each class\n",
    "colors = ['red', 'blue', 'green', 'purple', 'orange', 'yellow', 'black', 'pink', 'brown', 'gray']\n",
    "class_colors = {class_name: colors[i % len(colors)] for i, class_name in enumerate(numpy_mapping.keys())}\n",
    "\n",
    "# Plot data for each class\n",
    "for class_name, vectors in numpy_mapping.items():\n",
    "    sns.scatterplot(x=vectors[:, 0], y=vectors[:, 23], label=class_name, color=class_colors[class_name], s=20, alpha=0.5, ax=ax)\n",
    "\n",
    "# Add labels and legend\n",
    "ax.set_xlabel('Latent Dimension 1')\n",
    "ax.set_ylabel('Latent DImension 24')\n",
    "ax.legend()\n",
    "ax.set_title('Scatter plot of Dimension 1 vs Dimension 24')\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Intensity Levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is some structure behind the data.\n",
    "\n",
    "Now, we want to try to classify the ECG data based on the latent space representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the number of dimensions\n",
    "num_dimensions = 25\n",
    "\n",
    "# Combine data into a single DataFrame\n",
    "all_data = []\n",
    "all_labels = []\n",
    "for class_name, vectors in numpy_mapping.items():\n",
    "    all_data.append(vectors)\n",
    "    all_labels.extend([class_name] * len(vectors))\n",
    "\n",
    "all_data = np.vstack(all_data)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(all_data, columns=[f'dim{i+1}' for i in range(num_dimensions)])\n",
    "df['label'] = all_labels\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "df = shuffle(df, random_state=42)\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "\n",
    "print(X.head(3))\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Write code to classify the dataset into the different intensity classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your first task, you should classify the dataset into three subclasses.\n",
    "\n",
    "Please write code that:\n",
    "1. splits the dataset into a training and test set (choose a reasonable split percentage)\n",
    "2. trains a XGBoost classifier on it\n",
    "3. shows the final test classification accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: \n",
    "X_train, X_test, y_train, y_test = ...\n",
    "\n",
    "model = ...\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "test_accuracy = ...\n",
    "print(f'Test accuracy: {test_accuracy}')\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Solution:\n",
    "\"\"\"\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Train an XGBoost classifier\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate test classification score\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f'Test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = joblib.cpu_count()\n",
    "\n",
    "# Create a SHAP explainer with parallel computation\n",
    "explainer = shap.Explainer(model, X_train)\n",
    "#with joblib.parallel_backend('loky', n_jobs=num_cores):\n",
    "shap_values = explainer(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us analyze the importance of the latent space dimensions for specific classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the SHAP values for feature importance\n",
    "# shap.summary_plot(shap_values, X_train, feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapley Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we want to find out which dimensions have a strong influence on the prediction of class 0 (standstill).\n",
    "\n",
    "We can use a Beeswarm Plot for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values[:, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for class 0, low (blue) dim8 values are very descriptive. Analogously, we find that the model leant that high dim1 values (red) are descriptive for class 0.\n",
    "\n",
    "Let's check that visually in a 2D data plot as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the figure and axis\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "\n",
    "# Define colors for each class\n",
    "colors = ['red', 'blue', 'green', 'purple', 'orange', 'yellow', 'black', 'pink', 'brown', 'gray']\n",
    "class_colors = {class_name: colors[i % len(colors)] for i, class_name in enumerate(numpy_mapping.keys())}\n",
    "\n",
    "# Plot data for each class\n",
    "for class_name, vectors in numpy_mapping.items():\n",
    "    sns.scatterplot(x=vectors[:, 7], y=vectors[:, 0], label=class_name, color=class_colors[class_name], s=20, alpha=0.5, ax=ax)\n",
    "\n",
    "# Add labels and legend\n",
    "ax.set_xlabel('Latent Dimension 8')\n",
    "ax.set_ylabel('Latent DImension 1')\n",
    "ax.legend()\n",
    "ax.set_title('Scatter plot of Dimension 8 vs Dimension 1')\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot we can see that indeed, for class 0 (yellow), low dim8 and high dim0 values are observed frequently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Shapley Analysis cont."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have done an analysis for class 0 now.\n",
    "\n",
    "TODO:\n",
    "- Please repeat the analysis for class 3 now and also create a plot of descriptive features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Write code for creating a beeswarm plot for class 0.\n",
    "\"\"\"\n",
    "\n",
    "shap.plots.beeswarm(shap_values[:, :, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Write code for plotting the identified descriptive dimensions for visualization purposes.\n",
    "\"\"\"\n",
    "\n",
    "# Create the figure and axis\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "\n",
    "# Define colors for each class\n",
    "colors = ['red', 'blue', 'green', 'purple', 'orange', 'yellow', 'black', 'pink', 'brown', 'gray']\n",
    "class_colors = {class_name: colors[i % len(colors)] for i, class_name in enumerate(numpy_mapping.keys())}\n",
    "\n",
    "# Plot data for each class\n",
    "for class_name, vectors in numpy_mapping.items():\n",
    "    sns.scatterplot(x=vectors[:, 22], y=vectors[:, 23], label=class_name, color=class_colors[class_name], s=20, alpha=0.5, ax=ax)\n",
    "\n",
    "# Add labels and legend\n",
    "ax.set_xlabel('Latent Dimension 23')\n",
    "ax.set_ylabel('Latent DImension 24')\n",
    "ax.legend()\n",
    "ax.set_title('Scatter plot of Dimension 23 vs Dimension 24')\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Datapoint Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us create a plot of an individual sample:\n",
    "\n",
    "For that, we first identify the class of the first sample in our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"True Class: \", y_test.iloc[0])\n",
    "#Â print(\"Values: \\n\", X_test.iloc[0])\n",
    "\n",
    "x = X_test.iloc[[0]]\n",
    "y = model.predict(x)\n",
    "\n",
    "print(\"Predicted Class: \", y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we have seen that the true class of this datapoint is 5, which is also the predicted class.\n",
    "\n",
    "Now, let us take a look at the dimensions that contribute mostly to this prediction using a waterfall plot.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_x = explainer(x)\n",
    "shap.plots.waterfall(shap_values_x[0, :, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the specific values of the datapoint in dimensions dim25 ad dim1 strongly contribute to the classification.\n",
    "\n",
    "f(x) is a measure for the prediction of the datapoint x being in the observed class (in this case class 4). Here, f(x) is very high and hence the datapoint is classified as class 4 as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also make this analysis for the same datapoint for class 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values_x[0, :, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen that Shapley values and specifically the Python SHAP package can be used for explaining the XGBoost tree model, both for the whole dataset, for specific classes as well as for specific datapoints and individual feature contributions to the prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shaplecture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
